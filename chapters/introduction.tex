\chapter{Introduction}
\label{chap:intro}

In the rapidly evolving landscape of modern computing, an undeniable shift has taken place over the past decade. Computing no longer happens exclusively within the safe confines of dedicated, physically secured machines operated by trusted personnel. Instead, it is increasingly conducted across a wide array of environments that range from large-scale, multi-tenant cloud platforms to geographically dispersed edge devices deployed in untrusted, sometimes hostile, settings. These emerging scenarios offer unparalleled scalability, accessibility, and flexibility but simultaneously pose profound new challenges to the foundational assumptions upon which traditional system security models have long been based.

Consider, for example, a cloud computing environment where organizations lease computational resources from a third-party provider. While this model delivers significant economic and operational advantages, it necessarily requires placing sensitive data and critical computations on infrastructure controlled, at least in part, by entities outside the organization’s direct control. In such environments, the software stack—from firmware and bootloaders to the operating system and hypervisor—may be susceptible to compromise through vulnerabilities, misconfigurations, or even insider threats. Similarly, edge devices deployed in remote locations may operate without continuous physical supervision, making them vulnerable to physical tampering or software-based attacks. In all these cases, the question arises: how can one guarantee that sensitive computations execute correctly and confidentially, even when the underlying platform may be compromised or untrusted?

Traditional security approaches, such as enforcing access controls, employing encryption for data at rest or in transit, or leveraging virtualization-based isolation, offer important protections but are often insufficient in these adversarial contexts. These mechanisms fundamentally rely on the integrity of the underlying system software to enforce security policies. Once that trust is broken—for example, if a privileged kernel or hypervisor is subverted—malicious actors may gain unauthorized access to secrets, manipulate computations, or subvert the system’s intended behavior. As a result, there has been a growing recognition of the need for a fundamentally different approach: one that can provide strong guarantees about the confidentiality and integrity of code and data, even in the face of potentially compromised system components.

This pressing need has catalyzed the development of Trusted Execution Environments (TEEs), a class of hardware-assisted security mechanisms designed to establish a secure and isolated environment within an untrusted platform. A TEE creates a trusted “enclave” or protected region of execution where sensitive code and data reside, shielded from the rest of the system, including the operating system, hypervisor, and other software running on the host. By leveraging hardware features that enforce strict isolation and memory protection boundaries, TEEs aim to provide a sanctuary of trust—a secure vault in which computations can proceed without fear of interference or observation by unauthorized parties.

The promise of TEEs is compelling: they enable the secure execution of sensitive workloads such as cryptographic key management, digital rights enforcement, confidential cloud computing, and privacy-preserving data analytics. Over the past several years, commercial implementations have emerged, most notably Intel’s Software Guard Extensions (SGX) and ARM’s TrustZone technology, each offering unique approaches to enclave creation and hardware isolation. Intel SGX, for example, introduces user-space enclaves with hardware-enforced memory encryption and attestation capabilities, allowing remote verification of enclave authenticity. ARM TrustZone takes a different approach, partitioning the processor into Secure and Normal worlds to separate trusted code from the rest of the system.

Despite their successes and practical deployments, these commercial TEEs come with a number of significant limitations that hinder their applicability in research, experimental settings, and use cases requiring flexibility and transparency. Both SGX and TrustZone are proprietary technologies with closed-source implementations, limiting independent analysis, verification, and modification. Their architectural designs are relatively rigid, optimized for particular use cases, and do not easily accommodate novel security policies, alternative enclave management strategies, or supervisor-mode enclave execution. Moreover, their Trusted Computing Bases (TCBs) can be substantial, complicating efforts at formal verification and security assurance. These challenges collectively motivate the exploration of open, extensible TEE architectures that can empower researchers and practitioners to experiment, customize, and extend trusted execution mechanisms without the constraints imposed by proprietary solutions.

It is within this context that the Keystone framework has emerged as a pioneering open-source TEE architecture built atop the RISC-V instruction set architecture (ISA). RISC-V, an open and extensible ISA, has attracted substantial attention in academia and industry alike for its flexibility, simplicity, and openness. Keystone leverages these advantages to provide a modular, fully open TEE framework that supports fine-grained control over enclave behavior and a minimal trusted computing base. Notably, Keystone harnesses RISC-V’s hardware capabilities such as Physical Memory Protection (PMP) to implement hardware-enforced isolation, enabling dynamic enclave management and runtime configurability rarely available in existing TEEs.

Keystone’s open design philosophy not only facilitates deep architectural exploration and formal verification but also enables the development of novel security primitives and policies tailored to emerging application domains. Its modularity supports supervisor-level enclave components, dynamic loading, and interaction with Linux-based host environments, making it well-suited for research, prototyping, and education. However, the flexibility offered by Keystone comes with inherent challenges. For instance, RISC-V’s PMP architecture, while powerful, imposes a limited number of protection entries, constraining the number of concurrent enclaves and complicating memory management. Additionally, the performance overhead induced by enclave isolation—especially when executing memory-intensive or computationally demanding workloads such as post-quantum cryptographic algorithms—necessitates thorough empirical evaluation to guide practical deployment and future hardware design.

This thesis undertakes a comprehensive investigation of the Keystone framework, focusing on its architectural foundations, practical deployment in a fully virtualized RISC-V environment, and performance characteristics under representative workloads. Through methodical benchmarking using standard synthetic tests and cryptographic workloads, this work illuminates the complex trade-offs between security, performance, and scalability inherent to Keystone’s design. The study further documents the intricacies of configuring and debugging Keystone enclaves in an emulator, addressing the challenges posed by hardware constraints such as PMP entry exhaustion. By providing a rigorous empirical characterization of Keystone’s runtime behavior and scalability limits, this thesis contributes valuable insights to the open TEE community and lays the groundwork for future enhancements in RISC-V based secure execution environments.

In the following sections, this introduction will first articulate the specific contributions of this thesis in detail. It will then situate this work within the broader context of related research and commercial TEE developments. Finally, an overview of the thesis structure will guide the reader through the chapters that follow, setting the stage for an in-depth exploration of Keystone and its capabilities.

\section{Contributions of this Thesis}

This thesis makes several key contributions that advance the understanding and evaluation of Trusted Execution Environments, particularly focusing on the open-source Keystone framework and its RISC-V hardware foundation.

\begin{itemize}
    \item \textbf{Comprehensive Architectural Analysis:} A detailed exposition of Keystone’s design is presented, highlighting its Security Monitor (SM), enclave runtime, and user-level application interactions. This includes an exploration of how RISC-V’s privilege levels and Physical Memory Protection (PMP) mechanisms are employed to establish and enforce robust isolation boundaries between enclaves and untrusted system components.
    
    \item \textbf{Comparative Evaluation with Commercial TEEs:} The thesis performs a thorough comparative study positioning Keystone alongside Intel SGX and ARM TrustZone. This analysis elucidates key architectural distinctions, including enclave lifecycle management, privilege separation, Trusted Computing Base size, scalability, and extensibility. This contextualization highlights Keystone’s unique advantages in openness, modularity, and adaptability for research and experimentation.
    
    \item \textbf{Virtualized Deployment and Toolchain Documentation:} A fully virtualized deployment of Keystone is demonstrated using a RISC-V-specific QEMU emulator. This approach allows experimentation independent of physical hardware availability. The thesis provides detailed documentation of the build environment, toolchain configuration, emulator setup, and debugging workflows, establishing a reproducible methodology for future work.
    
    \item \textbf{Empirical Performance Evaluation:} Using established benchmarks such as Dhrystone and CoreMark, alongside a computationally demanding post-quantum cryptographic workload (Kyber), the thesis quantifies runtime overheads incurred by enclave isolation. It explores how varying system parameters—such as CPU core count, memory allocation, and cache sizes—affect enclave performance and stability.
    
    \item \textbf{Analysis of Hardware-Induced Scalability Constraints:} The limited number of PMP entries and its impact on enclave concurrency and lifecycle management is carefully analyzed. The thesis identifies bottlenecks and proposes strategies to mitigate the effects of PMP exhaustion on system scalability and enclave deployment.
    
    \item \textbf{Identification and Documentation of Runtime Failure Modes:} Through extensive testing, the thesis uncovers failure scenarios arising from PMP limitations and enclave memory protection policies, contributing practical insights and guidance to the Keystone community for improving robustness and fault tolerance.
\end{itemize}

\section{Related Work}

Trusted Execution Environments (TEEs) have become a cornerstone for securing computation on untrusted platforms by isolating sensitive code and data from the rest of the system. The landscape of TEE technologies includes Intel SGX, ARM TrustZone, AMD SEV, and emerging open-source frameworks like Keystone, each offering distinct security guarantees, performance trade-offs, and hardware dependencies.

Intel SGX~\cite{akkram2020scientific, kumar2022sgxgauge} provides strong confidentiality and integrity guarantees via isolated enclaves backed by hardware-enforced memory encryption. However, SGX suffers from limited enclave page cache (EPC) size, causing significant performance degradation when working sets exceed EPC limits, as observed by Kumar et al.~\cite{kumar2022sgxgauge}. Moreover, the overheads in enclave transitions and paging have been documented in multiple studies~\cite{akkram2020scientific, krahn2020teemon}.

ARM TrustZone~\cite{suzaki2021ts, turn0search8} takes a different approach by partitioning the processor into secure and normal worlds, enabling lightweight isolation for Trusted Applications but with generally weaker isolation guarantees than SGX. Its performance impact tends to be lower, yet TrustZone’s capabilities and APIs are less standardized, which complicates broad adoption and benchmarking~\cite{turn0search9}.

AMD SEV and newer technologies such as SEV-SNP offer memory encryption and integrity protections for virtual machines, providing scalable enclave-like isolation for cloud workloads. Coppolino et al.~\cite{turn0search2_coppolino} experimentally evaluated SEV and TDX against SGX, revealing performance and transparency trade-offs that influence their suitability for different application scenarios.

In parallel, open-source efforts like Keystone~\cite{Lee2019, dayeol2019keystone} aim to democratize TEE development by providing a modular framework on RISC-V processors, supporting flexible enclave configurations and custom security policies. Research into Keystone’s memory models and sharing mechanisms~\cite{yu2022elasticlave, lee2022cerberus} has demonstrated improved performance and formally verified security properties, addressing common TEE bottlenecks such as enclave memory management overhead.

Benchmarking and performance measurement frameworks are crucial to evaluate these TEEs fairly and holistically. TS-perf~\cite{suzaki2021ts} offers a unified performance suite targeting multiple TEE architectures, including SGX, TrustZone, and Keystone, facilitating comparative studies. Other benchmarking efforts include SGXGauge~\cite{kumar2022sgxgauge}, which specifically assesses Intel SGX overheads under different workload characteristics, and traditional CPU benchmarks like Dhrystone~\cite{weiss2002dhrystone, york2002benchmarking} and CoreMark~\cite{gal2012exploring}, adapted for enclave contexts.

Continuous monitoring tools like TEEMon~\cite{krahn2020teemon} help identify runtime bottlenecks by tracking enclave performance metrics with modest overheads, enabling dynamic optimization and debugging.

Recent surveys~\cite{Survey2023, turn0search5} provide comprehensive overviews of TEE design choices, common pitfalls, and application domains, highlighting the need for standardized performance evaluations and security validations.

While the state of the art has advanced significantly, challenges remain in balancing security, performance, and programmability across diverse hardware platforms and threat models. This work builds on these prior efforts by focusing on comprehensive performance evaluation across multiple TEEs using realistic workloads, emphasizing the modularity and transparency advantages offered by Keystone and comparing them with established commercial solutions.

\section{Structure of this Thesis}

This thesis is structured to progressively build the reader’s understanding of Trusted Execution Environments, with an emphasis on the Keystone framework and its RISC-V underpinnings. Each chapter deepens the narrative from foundational concepts to practical experimentation and critical analysis.

\begin{itemize}
    \item \textbf{Chapter~\ref{chap:intro}} lays the groundwork by introducing the motivation for secure computing in untrusted environments, detailing the contributions of this work, surveying relevant literature, and providing an overview of the thesis structure.
    
    \item \textbf{Chapter~\ref{chap:background}} presents essential background material on Trusted Execution Environments, the Keystone framework, and RISC-V architectural features such as Physical Memory Protection. It also introduces the Kyber post-quantum key encapsulation mechanism used as a cryptographic benchmark.
    
    \item \textbf{Chapter~\ref{chap:methodology}} describes the experimental setup, including the virtualized RISC-V testbed, benchmark selection criteria, parameter tuning, and measurement methodologies ensuring rigor and reproducibility.
    
    \item \textbf{Chapter~\ref{chap:benchmarking}} reports detailed empirical results exploring the performance impact of enclave isolation under different system configurations and workloads, identifying key overheads and architectural bottlenecks.
    
    \item \textbf{Chapter~\ref{chap:discussion}} synthesizes findings from prior chapters to discuss the trade-offs inherent in enclave design and execution, highlighting implications for future hardware and software secure computing architectures.
    
    \item \textbf{Chapter~\ref{chap:conclusion}} concludes the thesis by summarizing main contributions, reflecting on their broader significance, and outlining promising avenues for further research, including hardware extensions and formal verification approaches.
\end{itemize}
