\chapter{Benchmarking Results and Observations}
\label{chap:benchmarking}

This chapter presents a detailed empirical evaluation of the Keystone enclave framework, with a specific focus on its performance characteristics under a range of representative workloads. The primary aim is to quantify the computational and system-level overheads introduced by secure enclave execution on RISC-V platforms, and to explore how these overheads are influenced by underlying hardware configurations and architectural constraints. By systematically comparing enclave-based execution against native (non-isolated) execution, we aim to identify the key trade-offs and limitations that developers and system architects must consider when adopting enclaves for trusted execution.

To achieve this, we deploy a carefully selected set of benchmark workloads that span both general-purpose and security-critical application domains. These include the Dhrystone and CoreMark benchmarks—commonly used to assess CPU performance and embedded system efficiency—as well as the Kyber post-quantum cryptographic algorithm, which provides a real-world workload with stringent security and computational requirements. Together, these benchmarks provide a diverse and comprehensive view of how Keystone enclaves behave across different execution contexts.

The benchmarking process is structured to examine four interrelated dimensions. First, we establish a native performance baseline to isolate the impact of enclave-related operations. Second, we evaluate the performance of the same workloads when executed within enclaves, highlighting the latency and resource costs incurred by isolation mechanisms such as Physical Memory Protection (PMP) and context switching. Third, we perform a workload sensitivity analysis, comparing the behavior of different benchmark types—sequential vs. parallel, lightweight vs. compute-intensive—to determine how workload characteristics affect enclave performance. Finally, we assess the influence of key hardware parameters, including CPU core count, memory size, and cache configuration, on both native and enclave execution.

Through these experiments, we uncover both expected and non-trivial behaviors. For instance, while enclave overheads are generally modest—typically under 15\%—they are highly sensitive to parallelism and memory access patterns. Furthermore, we identify critical bottlenecks, such as the fixed number of PMP entries available for isolating memory regions, which directly limit enclave concurrency and scalability.

The results presented in this chapter serve as the empirical foundation for the interpretive analysis in the next chapter. By rigorously characterizing the performance profile of Keystone enclaves, we establish a data-driven basis for understanding the broader implications of enclave deployment in secure system design, as well as informing practical strategies for optimization and resource management.

\section{Baseline: Native (Non-Enclave) Performance}
\label{sec:baseline-native}

To accurately assess the performance overheads imposed by secure enclave execution, it is imperative to begin with a rigorously characterized baseline: one that isolates application-level behavior from security mechanisms, scheduling anomalies, and hardware acceleration artifacts. This section documents such a baseline, derived from native (non-enclave) execution of representative workloads on a deterministic, single-core RISC-V simulation environment. All benchmarks were executed under the Low-End Baseline configuration, designed to approximate the resource constraints of a lightweight embedded platform: 64~MB of main memory, a single in-order RISC-V core, and no parallelism beyond sequential instruction issue. This environment intentionally excludes vector extensions, out-of-order speculation, and memory prefetching, ensuring that measured performance reflects algorithmic structure rather than microarchitectural opportunism.

Each benchmark was executed both \emph{sequentially} and \emph{in parallel}, ten times each, and the resulting figures compare performance and stability across both modes.

% ------------------------
% Wall-clock time figures
% ------------------------
Figure~\ref{fig:coremark_perf_comparison_log} reports CoreMark's performance profile using the latest data from Run~10 of both sequential and parallel execution modes. Execution time remained consistent, with the sequential case averaging approximately 101.17 seconds of wall-clock time and the parallel case averaging around 103.37 seconds. This corresponds to an effective throughput of about 988.4 iterations per second for the sequential run and 967.4 iterations per second for the parallel run. User-mode CPU time dominated in both cases (101.20 seconds sequential, 103.39 seconds parallel), accounting for over 99.9\% of total CPU time. System-mode CPU time was negligible (under 0.03 seconds), confirming that the workload’s operational footprint is almost entirely in user space with minimal reliance on system calls or kernel transitions.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \begin{tikzpicture}
        \begin{axis}[
            ybar,
            bar width=8pt,
            width=\textwidth,
            height=8cm,
            ymode=log,
            log origin=infty,
            ymin=0.001,
            ylabel={Value (log scale)},
            symbolic x coords={
                Total\ Time,
                Iterations/Sec,
                User\ CPU\ Time,
                System\ CPU\ Time,
                Max\ RSS,
                Minor\ PF,
                Major\ PF,
                Voluntary\ CS,
                Involuntary\ CS
            },
            xtick=data,
            x tick label style={rotate=30, anchor=east},
            enlarge x limits=0.05,
            ymajorgrids,
            grid style=dashed,
            legend style={at={(0.5,-0.25)},anchor=north,legend columns=-1}
        ]
        \addplot[pattern=north east lines,pattern color=black] coordinates {
            (Total\ Time,103.24)
            (Iterations/Sec,968.64)
            (User\ CPU\ Time,103.26)
            (System\ CPU\ Time,0.02)
            (Max\ RSS,1712.00)
            (Minor\ PF,83.60)
            (Major\ PF,0.20)
            (Voluntary\ CS,0.70)
            (Involuntary\ CS,25815.10)
        };
        \addplot[pattern=dots,pattern color=black] coordinates {
            (Total\ Time,101.11)
            (Iterations/Sec,989.00)
            (User\ CPU\ Time,101.14)
            (System\ CPU\ Time,0.01)
            (Max\ RSS,1691.60)
            (Minor\ PF,83.60)
            (Major\ PF,0.20)
            (Voluntary\ CS,0.90)
            (Involuntary\ CS,350.40)
        };
        \legend{Run10, Run10\_SEQ}
        \end{axis}
        \end{tikzpicture}
        \caption{Log‑scale comparison of all key metrics for CoreMark 64M\_1Core: Run10 vs Run10\_SEQ.}
        \label{fig:coremark_perf_comparison_log}
    \end{subfigure}

    \vspace{1.2cm}

    \begin{subfigure}{\textwidth}
        \centering
        \begin{tikzpicture}
        \begin{axis}[
            ybar,
            bar width=8pt,
            width=\textwidth,
            height=8cm,
            ymode=log,
            log origin=infty,
            ymin=0.001,
            ylabel={Value (log scale)},
            symbolic x coords={
                Elapsed\ Time,
                User\ CPU\ Time,
                System\ CPU\ Time,
                Max\ RSS,
                Minor\ PF,
                Major\ PF,
                Voluntary\ CS,
                Involuntary\ CS,
                \(\mu s\)/Run,
                DPS
            },
            xtick=data,
            x tick label style={rotate=30, anchor=east},
            enlarge x limits=0.05,
            ymajorgrids,
            grid style=dashed,
            legend style={at={(0.5,-0.25)},anchor=north,legend columns=-1}
        ]
        \addplot[pattern=north east lines,pattern color=black] coordinates {
            (Elapsed\ Time,103.74)
            (User\ CPU\ Time,11.04)
            (System\ CPU\ Time,0.02)
            (Max\ RSS,1700.00)
            (Minor\ PF,89.60)
            (Major\ PF,0.30)
            (Voluntary\ CS,0.70)
            (Involuntary\ CS,2583.60)
            (\(\mu s\)/Run,10.10)
            (DPS,96478.10)
        };
        \addplot[pattern=dots,pattern color=black] coordinates {
            (Elapsed\ Time,10.02)
            (User\ CPU\ Time,10.03)
            (System\ CPU\ Time,0.01)
            (Max\ RSS,1700.00)
            (Minor\ PF,88.60)
            (Major\ PF,0.10)
            (Voluntary\ CS,0.80)
            (Involuntary\ CS,44.00)
            (\(\mu s\)/Run,0.50)
            (DPS,998646.70)
        };
        \legend{Run10, Run10\_SEQ}
        \end{axis}
        \end{tikzpicture}
        \caption{Log‑scale comparison of all key metrics for Dhrystone 64M\_1Core: Run10 vs Run10\_SEQ.}
        \label{fig:dhrystone_perf_comparison_log}
    \end{subfigure}
    \caption{Comparison of CoreMark and Dhrystone benchmark performance metrics (log-scale) under Run10 and Run10\_SEQ modes.}
\end{figure}

% ------------------------
% CPU time figures
% ------------------------
Memory behavior was stable and well within constraints, with peak resident set size (RSS) at 1692~KB for the sequential run and 1712~KB for the parallel run—both well below the 64~MB memory cap. This indicates that the benchmark’s data and code footprint remained fully cacheable, without triggering paging or dynamic memory expansion. Minor page faults were low and consistent (82--84 for sequential, 82--85 for parallel), though a single major page fault was observed in the parallel run and two in the sequential run, suggesting rare but possible demand paging during lazy allocation. Voluntary context switches were minimal (0--1 sequential, 0--3 parallel), while involuntary context switches showed a stark contrast: approximately 350 in the sequential case versus over 25,800 in the parallel case. This disparity reflects a significantly higher degree of preemption or timer interrupts in the parallel workload environment.

% ------------------------
% Throughput figures
% ------------------------
Figure~\ref{fig:dhrystone_perf_comparison_log} presents detailed results from the Dhrystone benchmark under native conditions. The sequential runs exhibited an average elapsed time of approximately 101.2 seconds per run, with user-mode CPU time closely matching this figure, indicating near-total CPU utilization. In contrast, the parallel merged runs completed in roughly 103.4 seconds, with user CPU time again nearly equal to wall-clock time. Throughput, measured in Dhrystone operations per second (DPS), was higher in the sequential case—approximately 988.4~DPS versus 967.4~DPS in the parallel configuration—reflecting slight scheduling overhead from virtual concurrency under QEMU.

% ------------------------
% Memory usage figures
% ------------------------
Memory footprint remained small (peak RSS ~1.7~MB) and stable, with 82--86 minor page faults per run.

% ------------------------
% Context switches figures
% ------------------------
Voluntary context switches were minimal (0--1 sequential, 0--3 parallel), while involuntary context switches showed a stark contrast: approximately 350 in the sequential case versus over 25,800 in the parallel case.

% ------------------------
% Cycle counts figures (Kyber only)
% ------------------------
Kyber performance was evaluated using the official \texttt{test\_speed512} binary from the reference implementation's \texttt{ref/} directory.\footnote{See \url{https://github.com/pq-crystals/kyber}. The \texttt{test\_speed512} tool benchmarks key operations using emulated cycle counters in QEMU.} Figure~\ref{fig:kyber_median_cycles_chart_log} presents the median cycle counts for each cryptographic operation, comparing both sequential and parallel enclave execution.

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.9\linewidth]{figures/kyber_64M_1Core.pdf}
%     \caption{Comparison of Kyber Median CPU Cycles per Operation: Sequential Single-Threaded (\texttt{run10\_SEQ}) vs Parallel Merged (\texttt{run10}) Execution (10 Runs)}
%     \label{fig:kyber_native_cycles}
% \end{figure}

All cryptographic operations executed entirely in user space, without invoking privileged instructions or incurring system-level overhead. Memory footprint remained minimal (peak RSS ~10~KB), with only a single minor page fault observed across all runs.

\begin{figure}[h]
\centering
\begin{tikzpicture}
\begin{axis}[
    ybar,
    bar width=10pt,
    width=14cm,
    height=8cm,
    ymode=log,
    log origin=infty,
    ymin=1e5,
    ymax=1e9,
    ytick={1e5,1e6,1e7,1e8,1e9},
    yticklabels={10$^5$,10$^6$,10$^7$,10$^8$,10$^9$},
    ylabel={Median CPU Cycles (log scale)},
    symbolic x coords={
        indcpa\_keypair,
        indcpa\_enc,
        indcpa\_dec,
        kyber\_keypair,
        kyber\_encaps,
        kyber\_decaps
    },
    xtick=data,
    x tick label style={rotate=30, anchor=east},
    enlarge x limits=0.05,
    ymajorgrids,
    grid style=dashed,
    legend style={at={(0.5,-0.25)},anchor=north,legend columns=-1},
    nodes near coords,
    every node near coord/.append style={font=\scriptsize, rotate=90, anchor=west}
]
% Parallel values
\addplot[pattern=north east lines,pattern color=black] coordinates {
    (indcpa\_keypair,1870200)
    (indcpa\_enc,38376800)
    (indcpa\_dec,39060800)
    (kyber\_keypair,1870200)
    (kyber\_encaps,38376800)
    (kyber\_decaps,39060800)
};
% Sequential values
\addplot[pattern=dots,pattern color=black] coordinates {
    (indcpa\_keypair,1702800)
    (indcpa\_enc,2174400)
    (indcpa\_dec,618400)
    (kyber\_keypair,1800300)
    (kyber\_encaps,2285900)
    (kyber\_decaps,2921800)
};

\legend{Parallel, Sequential}
\end{axis}
\end{tikzpicture}
\caption{Median CPU cycles for Kyber operations in parallel vs sequential modes, plotted on a logarithmic scale to make smaller values visible alongside large ones.}
\label{fig:kyber_median_cycles_chart_log}
\end{figure}

Across all three workloads, cache behavior was uniformly stable. Monitoring via QEMU’s cache plugin confirmed low instruction and data cache miss rates, consistent with compact memory footprints and tight loop-local access patterns. Instruction cache performance benefited from small binary sizes and the absence of dynamic control flow, while data cache pressure remained minimal due to statically sized inputs and short-lived stack allocations. These characteristics consistently indicate compute-bound, not memory-bound, behavior in the native case.

Together, these results confirm that the native execution environment offers a low-noise, deterministic baseline across benchmarks. Variability was minimal, CPU time aligned closely with wall-clock time, memory remained well-bounded, and system-level interference was negligible—making this configuration ideal for isolating performance effects introduced in subsequent secure or enclave-based execution modes.

\section{Enclave Execution Results and Overheads}
\label{sec:enclave-execution}

Building on the native baseline characterization, this section analyzes the performance impacts and system overheads observed when executing representative workloads—Kyber, Dhrystone, and CoreMark—within a secure enclave environment. The experiments were conducted on the identical Low-End Baseline platform (64~MB RAM, single in-order RISC-V core), isolating overheads introduced exclusively by enclave security mechanisms such as memory encryption, integrity verification, and enclave runtime management.

All benchmarks were initially executed ten times sequentially under enclave protection to establish a direct, low-variability comparison against native runs. The Kyber \texttt{kyber\_decaps} operation exhibited median CPU cycle counts consistently around 3.5 million cycles per run (e.g., 3,505,686 cycles in Run~1), approximately 1.2$\times$ the native sequential baseline of about 2.9 million cycles (see Figure~\ref{fig:kyber_median_cycles_chart_log}). Average cycles were slightly higher, around 3.53 million, reflecting stable and repeatable enclave performance. Other key Kyber operations, such as \texttt{indcpa\_keypair} and \texttt{indcpa\_enc}, showed median cycle counts near 1.74 million and 2.62 million cycles respectively, consistent across runs.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.7\textwidth]{figures/kyber_64M_1Core_comparison.pdf}
%     \caption{Cycle count comparison for Kyber operations (native vs enclave). Error bars reflect variation over 10 runs.}
%     \label{fig:kyber_cycles}
% \end{figure}

Corresponding wall-clock times for these Kyber enclave runs averaged approximately 29.3 seconds, significantly exceeding native baselines of 10--11 seconds, primarily due to cryptographic memory encryption and integrity checks that increase the cost of each memory access and instruction fetch.

% \begin{figure}[h]
% \centering
% \begin{tikzpicture}

% % --- Left axis: Times + slowdown factors ---
% \begin{axis}[
%     ybar,
%     bar width=8pt,
%     width=14cm,
%     height=8cm,
%     ymin=0,
%     ymax=120,
%     ylabel={Time (s) / Slowdown ×},
%     symbolic x coords={Kyber,Dhrystone,CoreMark},
%     xtick=data,
%     enlarge x limits=0.35,
%     ymajorgrids,
%     grid style=dashed,
%     legend style={at={(0.5,-0.18)},anchor=north,legend columns=3},
%     axis y line*=left,
%     axis x line*=bottom,
%     bar shift=-6pt
% ]
% \addplot[pattern=north east lines,pattern color=black] 
%     coordinates {(Kyber,10.65) (Dhrystone,15.3) (CoreMark,101)};
% \addplot[pattern=dots,pattern color=black] 
%     coordinates {(Kyber,29.3) (Dhrystone,24.7) (CoreMark,107)};
% \addplot[pattern=crosshatch,pattern color=black] 
%     coordinates {(Kyber,2.6) (Dhrystone,1.6) (CoreMark,1.05)};
% \legend{Native time (s), Enclave time (s), Slowdown ×}
% \end{axis}

% % --- Right axis: Context switches ---
% \begin{axis}[
%     ybar,
%     bar width=8pt,
%     width=14cm,
%     height=8cm,
%     ymin=0,
%     ymax=70000,
%     ylabel={Involuntary Context Switches},
%     symbolic x coords={Kyber,Dhrystone,CoreMark},
%     xtick=data,
%     enlarge x limits=0.35,
%     hide x axis,
%     axis y line*=right,
%     axis x line=none,
%     bar shift=10pt
% ]
% \addplot[pattern=horizontal lines,pattern color=black] 
%     coordinates {(Kyber,66000) (Dhrystone,66000) (CoreMark,66000)};
% \legend{Involuntary CS}
% \end{axis}

% \end{tikzpicture}
% \caption{Native vs enclave performance: absolute times, slowdown factors (left axis), and involuntary context switches (right axis).}
% \end{figure}

Memory footprint across enclave runs remained tightly constrained near 10~KB RSS, mirroring native conditions. Page faults were minimal, with typically one minor page fault and zero major faults per run, indicating effective enclave memory management without paging overhead.

\begin{figure}[htbp]
\centering
\begin{tikzpicture}
\begin{axis}[
    ybar,
    bar width=12pt,
    width=12cm,
    height=7cm,
    ymin=0,
    ylabel={Value},
    symbolic x coords={RSS\ (KB), Minor\ PF, Major\ PF},
    xtick=data,
    enlarge x limits=0.25,
    ymajorgrids,
    grid style=dashed,
    legend style={at={(0.5,-0.18)},anchor=north,legend columns=-1}
]
% Native values
\addplot[pattern=north east lines,pattern color=black] coordinates
    {(RSS\ (KB),10) (Minor\ PF,1) (Major\ PF,0)};
% Enclave values
\addplot[pattern=dots,pattern color=black] coordinates
    {(RSS\ (KB),10) (Minor\ PF,1) (Major\ PF,0)};

\legend{Native, Enclave}
\end{axis}
\end{tikzpicture}
\caption{Kyber benchmark: memory usage (RSS) and page fault counts for native vs enclave execution.}
\label{fig:memory_pagefaults_chart}
\end{figure}

A notable system-level overhead manifested in the form of a dramatic increase in involuntary context switches—approximately 66,000 per run, nearly two orders of magnitude above the roughly 350 switches observed natively. This surge likely reflects enclave runtime activities such as page re-encryption cycles, secure interrupt handling, and frequent enclave scheduler invocations. While these involuntary context switches contribute to wall-clock time variability, user-mode CPU time remained dominant (over 95\% of total CPU time), confirming that computation remains primarily enclave-resident and compute-bound.

\begin{figure}[htbp]
\centering
\begin{tikzpicture}
% Left axis: CPU time percentages
\begin{axis}[
    ybar,
    bar width=8pt,
    width=14cm,
    height=8cm,
    ymin=0,
    ymax=100,
    ylabel={CPU Time (\%)},
    symbolic x coords={Kyber,Dhrystone,CoreMark},
    xtick=data,
    enlarge x limits=0.25,
    ymajorgrids,
    grid style=dashed,
    legend style={at={(0.5,-0.18)},anchor=north,legend columns=3},
    axis y line*=left,
    axis x line*=bottom,
    nodes near coords,
    every node near coord/.append style={
        font=\small,
        anchor=west,
        rotate=90
    }
]

% User CPU% Native
\addplot[pattern=dots,pattern color=black] coordinates
    {(Kyber,95) (Dhrystone,95) (CoreMark,95)};

% User CPU% Enclave
\addplot[pattern=dots,pattern color=black!50] coordinates
    {(Kyber,95) (Dhrystone,95) (CoreMark,95)};

% System CPU% Native
\addplot[pattern=crosshatch,pattern color=black] coordinates
    {(Kyber,5) (Dhrystone,5) (CoreMark,5)};

% System CPU% Enclave
\addplot[pattern=crosshatch,pattern color=black!50] coordinates
    {(Kyber,5) (Dhrystone,5) (CoreMark,5)};

\legend{
    User CPU\% (Native),
    User CPU\% (Enclave),
    System CPU\% (Native),
    System CPU\% (Enclave),
    Ctx Switches (Native),
    Ctx Switches (Enclave)
}
\end{axis}

% Right axis: Context switches
\begin{axis}[
    ybar,
    bar width=8pt,
    width=14cm,
    height=8cm,
    ymin=0,
    ymax=70000,
    ylabel={Involuntary Context Switches},
    symbolic x coords={Kyber,Dhrystone,CoreMark},
    xtick=data,
    enlarge x limits=0.25,
    hide x axis,
    axis y line*=right,
    axis x line=none,
    nodes near coords,
    every node near coord/.append style={
        font=\small,
        anchor=west,
        rotate=90
    }
]

% Context switches Native
\addplot[pattern=north east lines,pattern color=black] coordinates
    {(Kyber,350) (Dhrystone,350) (CoreMark,350)};

% Context switches Enclave
\addplot[pattern=north east lines,pattern color=black!50] coordinates
    {(Kyber,66000) (Dhrystone,66000) (CoreMark,66000)};

\end{axis}

\end{tikzpicture}
\caption{Native vs enclave execution: involuntary context switches (right axis) and CPU time percentages (left axis).}
\label{fig:context_switches_dualaxis}
\end{figure}

The Dhrystone benchmark demonstrated a similar pattern, with wall-clock times averaging 24.7 seconds under enclave protection, roughly 1.6$\times$ slower than the native 15.3-second average. User and system CPU times both rose to near 41 seconds, reflecting the combined cost of enclave runtime overheads and cryptographic memory protection. Throughput, measured in Dhrystone operations per second, declined modestly to the 395,000--408,000 DPS range from a native baseline near 400,000 DPS. Memory consumption and page fault rates stayed consistent with Kyber’s enclave runs, and involuntary context switch counts remained elevated near 66,000 per run.

CoreMark enclave runs averaged 107 seconds wall-clock time—about 1.05$\times$ slower than the 101-second native average—with throughput dropping to 919--939 iterations per second compared to the native 967--988 range. CPU time profiles and memory usage mirrored the trends seen in Kyber and Dhrystone, reinforcing a stable but nontrivial enclave overhead footprint.

Beyond sequential execution, attempts to scale enclave workloads via parallelism revealed critical hardware-enforced constraints. Specifically, running 10 concurrent parallel enclave instances consistently failed due to exhaustion or conflicts in Physical Memory Protection (PMP) region allocation. This limitation manifested as execution aborts or enclave crashes, highlighting the sensitivity of enclave concurrency to limited hardware memory isolation resources.

Reducing parallelism to 5 simultaneous runs yielded improved but still imperfect stability: intermittent failures occurred less frequently, suggesting that PMP regions remain a bottleneck under moderate concurrency levels. Nevertheless, the 5$\times$ parallel configuration was generally capable of completing most benchmark runs.

In contrast, 2$\times$ parallel enclave runs executed reliably with no PMP-related failures, though at the expected overhead cost relative to native concurrency. Additionally, all 10 sequential enclave runs were stable and completed successfully, underscoring sequential execution as the most dependable operational mode given current PMP constraints.

% \begin{figure}[htbp]
%   \centering
%   \includegraphics[width=0.75\linewidth]{figures/enclave_parallelism_stability.png}
%   \caption{Effect of parallel enclave instances on execution stability. Failures increase sharply beyond 5 concurrent runs due to PMP region limitations.}
%   \label{fig:parallelism_stability}
% \end{figure}

These results underscore a fundamental trade-off in enclave execution scalability: while parallelism can improve throughput, strict hardware PMP enforcement imposes hard limits on enclave concurrency that manifest as failures at higher parallel counts. Addressing this will likely require advances in PMP management, dynamic region allocation, or hardware extensions to support larger concurrent enclave workloads without compromising memory protection guarantees.

Enclave execution imposes moderate but consistent performance overheads relative to native runs, with cycle counts and execution times increasing approximately 20--60\%. Memory usage remains tightly bounded, and paging is effectively avoided. The most substantial system-level overhead is the marked increase in involuntary context switches during enclave operation, which affects timing predictability but not computational correctness.

In summary, enclave execution on this low-end RISC-V platform introduces moderate but consistent overheads, primarily in the form of increased runtime and context switching, without significant memory bloat or paging pressure. While sequential workloads complete reliably, attempts at concurrent enclave execution expose hard architectural limits rooted in PMP region constraints. These results highlight the current scalability boundaries of enclave systems and motivate the need for both software- and hardware-level support to unlock robust parallelism under secure execution.

\section{Comparative Overhead Metrics Across Workloads}
\label{sec:workload-sensitivity}

This section presents a comparative evaluation of the performance overheads introduced by secure enclave execution across three representative workloads: the Kyber post-quantum cryptographic scheme, the Dhrystone integer benchmark, and the CoreMark embedded systems benchmark. These workloads were selected for their diversity in computational characteristics—ranging from cryptography-heavy operations with irregular memory access patterns, to synthetic instruction-driven integer arithmetic, and finally to mixed workload execution involving control logic, arithmetic, and memory access. By comparing enclave and native performance across these distinct benchmarks, we aim to empirically characterize how enclave runtime behavior and hardware-level protections interact with different application classes.

All experiments were conducted on the same low-end RISC-V platform: a single in-order core with 64~MB of RAM and no hardware acceleration for encryption or virtualization. Both enclave and native executions used the same compiler flags, runtime configurations, and benchmarking scripts. Each benchmark was run ten times sequentially in both native and enclave modes to minimize measurement noise and provide stable median and average performance statistics. Measurements included CPU cycle counts, wall-clock time, throughput (where applicable), context switches, and memory footprint.

Among the workloads tested, Kyber was the most sensitive to enclave-related overhead. In native execution, the \texttt{kyber\_decaps} operation completed in a median of approximately 2.9 million cycles, corresponding to a wall-clock time of around 10.7 seconds. However, under enclave execution, the same operation required over 3.5 million cycles and a wall-clock time of 29.2 seconds, reflecting a 2.73$\times$ increase in observed duration. The increase in cycle count—approximately 20\%—was dwarfed by the nearly 3$\times$ increase in elapsed time, suggesting that the overhead is not merely computational but also systemic. The Kyber implementation is particularly sensitive to memory access latency due to its reliance on large data buffers, frequent pointer dereferencing, and memory-intensive operations such as polynomial multiplication and compression. These characteristics make it acutely vulnerable to the latency overhead introduced by enclave-specific features such as memory encryption and integrity verification, which intercept and transform nearly every memory read and write.

By contrast, CoreMark exhibited far greater resilience to enclave-induced slowdown. The native execution time averaged 101.5 seconds, while enclave execution required 107.3 seconds—a modest 1.06$\times$ slowdown. Throughput dropped slightly from a native range of 967--988 iterations per second to an enclave range of 919--939, indicating that while performance was affected, the impact was minimal relative to the workload's duration and structure. This result is consistent with CoreMark’s design as a balanced benchmark that includes control flow, integer operations, and limited memory activity. The longer total runtime may also help amortize fixed enclave setup and teardown costs over a larger instruction volume, dampening the perceived overhead.

Figure~\ref{fig:sensitivity-overheads-chart} summarizes the comparative performance and system-level behavior across all three benchmarks, illustrating the wall-clock time overheads and the uniformly high context switch counts observed during enclave execution.

Dhrystone, a classic synthetic benchmark designed to test CPU and compiler performance through tight integer loops and frequent procedure calls, showed intermediate sensitivity. Its native execution time averaged 15.3 seconds, while the enclave variant took 24.7 seconds—an overhead factor of approximately 1.61$\times$. Unlike Kyber, Dhrystone does not perform extensive memory operations, but its compact and time-sensitive control loops make it vulnerable to any systemic delay introduced by the enclave runtime, particularly if context switches or instruction fetch penalties are frequent. Its throughput dropped slightly, from around 400,000 operations per second natively to a range between 395,000 and 408,000 in the enclave, with the decline being small but consistent.

Across all three benchmarks, a consistent and striking overhead pattern emerged in the form of involuntary context switches. While native executions averaged fewer than 400 involuntary context switches per run, enclave executions across all workloads exhibited approximately 66,000 context switches per run—an increase of nearly two orders of magnitude. This effect was uniform across workloads, suggesting that it is driven by enclave runtime behavior rather than application-specific activity. Likely contributors include timer interrupts, enclave runtime transitions, secure fault handling, and scheduling-related activity under the Keystone framework. Despite this significant increase, the impact on user-mode computation was minimal in terms of CPU time distribution: more than 95\% of execution time was consistently spent in user space, indicating that the workload remained compute-bound and that the primary cost of context switching was time variability rather than computational interference.

Memory usage was consistent and tightly constrained across all runs. All workloads exhibited a resident set size (RSS) of approximately 10~KB in both enclave and native executions, with no major page faults and typically only a single minor page fault per run. This indicates that working sets for each benchmark fit entirely within the secure memory allocation provided by the enclave runtime, and that the paging subsystem—despite operating in a protected mode—remained effective and unobtrusive. This stability is particularly noteworthy given the limited RAM available and the additional overhead of enclave memory isolation mechanisms.

Taken together, the data suggests that the performance impact of enclave execution is highly dependent on the nature of the workload. Kyber, with its pointer-heavy, memory-intensive cryptographic routines, suffers the most under enclave constraints, particularly due to the latency introduced by secure memory mechanisms. Dhrystone, while less affected, still shows measurable sensitivity due to its reliance on fast, loop-driven control structures. CoreMark, in contrast, demonstrates a relatively minor slowdown, benefiting from workload diversity and longer runtime that dilutes per-access costs. At the system level, enclave-induced context switching is a universal phenomenon, independent of workload type, but it does not appear to disrupt user-mode execution beyond timing variability.

\begin{figure}[htbp]
\centering
\begin{tikzpicture}

% --- Left axis: Execution times ---
\begin{axis}[
    ybar,
    bar width=6pt,
    width=14cm,
    height=8cm,
    ymin=0,
    ymax=120,
    ylabel={Execution Time (s)},
    symbolic x coords={Kyber,Dhrystone,CoreMark},
    xtick=data,
    enlarge x limits=0.4,
    ymajorgrids,
    grid style=dashed,
    legend style={at={(0.5,-0.18)},anchor=north,legend columns=3},
    axis y line*=left,
    axis x line*=bottom,
    bar shift=-4pt
]
% Native time
\addplot[pattern=dots,pattern color=black] 
    coordinates {(Kyber,10.7) (Dhrystone,15.3) (CoreMark,101.5)};

% Enclave time + overhead factor labels
\addplot[
    pattern=dots,
    pattern color=black!50,
    nodes near coords,
    point meta=explicit symbolic,
    every node near coord/.append style={
        font=\small,
        anchor=south,
        yshift=2pt,
        fill=white,
        fill opacity=0.7,
        text opacity=1
    }
] 
coordinates {
    (Kyber,29.2)      [2.73$\times$]
    (Dhrystone,24.7)  [1.61$\times$]
    (CoreMark,107.3)  [1.06$\times$]
};

\legend{Native Time, Enclave Time}
\end{axis}

% --- Right axis: Context switches ---
\begin{axis}[
    ybar,
    bar width=6pt,
    width=14cm,
    height=8cm,
    ymin=0,
    ymax=70000,
    ylabel={Involuntary Context Switches},
    symbolic x coords={Kyber,Dhrystone,CoreMark},
    xtick=data,
    enlarge x limits=0.4,
    hide x axis,
    axis y line*=right,
    axis x line=none,
    bar shift=10pt
]
\addplot[pattern=north east lines,pattern color=black] 
    coordinates {(Kyber,66000) (Dhrystone,66000) (CoreMark,66000)};
\legend{Involuntary CS}
\end{axis}

\end{tikzpicture}
\caption{Comparison of native and enclave execution times (left axis) with slowdown factors annotated, and involuntary context switch counts (right axis).}
\label{fig:sensitivity-overheads-chart}
\end{figure}

Overall, the impact of enclave execution overheads varies sharply by workload class, with memory-intensive cryptographic routines like Kyber suffering the most, and compute-dominant tasks like CoreMark showing minimal disruption. Importantly, system-level costs such as context switching appear invariant to workload structure, suggesting that certain overheads are intrinsic to enclave runtime design rather than application behavior. These distinctions are critical for guiding future secure system optimizations, especially in embedded or resource-constrained environments.    

Among the evaluated workloads, \texttt{coremark} stood out as the only one to exhibit consistent, positive scaling behavior. Performance improved by approximately 40.8\% with each additional core, and a similarly proportional uplift was observed with increased memory. This result is aligned with earlier observations: CoreMark’s mixed-instruction profile and parallelism-friendly design allow it to exploit both increased computational throughput and expanded memory capacity. As a compute-bound benchmark with moderate data locality, CoreMark scales predictably and efficiently with additional hardware provisioning.

In contrast, other workloads revealed far less favorable scaling characteristics. \texttt{Dhrystone}, for example, degraded by an average of 27.3\% per increment in either core or memory capacity. This counterintuitive result likely stems from architectural inefficiencies introduced by scaling: increased cache contention, ineffective parallel scheduling, or synchronization overheads may all contribute to this decline. Given Dhrystone’s tightly looped, serial control flow, its structure inherently resists parallelization and may suffer under hardware configurations that introduce unnecessary execution complexity.

Similarly, the \texttt{kyber} benchmark exhibited performance degradation averaging 26.1\% with increased cores and memory. These declines reflect Kyber’s sensitivity to memory hierarchy disruptions and suggest that parallelism may exacerbate contention for shared resources or increase memory access latency in unpredictable ways. Given Kyber’s cryptographic design, which involves frequent pointer dereferencing and buffer manipulation, increased hardware does not necessarily translate into improved performance and may instead magnify system-level inefficiencies.

For enclave-protected variants—\texttt{coremark.ke}, \texttt{enclave.ke}, and \texttt{kyber.ke}—the effect of hardware scaling was largely negligible. Across all test configurations, performance remained flat, indicating that these workloads are fundamentally bottlenecked by enclave runtime constraints rather than available compute or memory resources. Single-threaded enclave runtimes, fixed enclave memory regions, and serialization of cryptographic protections (e.g., memory encryption, page integrity) all limit the extent to which additional hardware can be utilized. These behaviors reinforce the architectural ceiling imposed by current enclave frameworks, especially under Physical Memory Protection (PMP) constraints observed earlier.


\section{Performance Sensitivity to Core and Memory Scaling}
\label{sec:hardware-impact}

Building on the preceding workload-specific performance analysis, this section investigates whether increasing CPU cores or available memory yields measurable performance improvements on our constrained RISC-V platform. Unlike traditional systems where scaling typically leads to linear or super-linear speedups, embedded systems with TEEs face distinct bottlenecks—such as synchronization overheads, memory bandwidth limits, and enclave management costs—that may inhibit or even reverse expected performance trends.

We systematically evaluated six representative workloads across multiple hardware configurations, incrementally increasing CPU core count and physical memory. The workloads include both native and enclave variants: \texttt{coremark}, \texttt{coremark.ke}, \texttt{dhrystone}, \texttt{enclave.ke}, \texttt{kyber}, and \texttt{kyber.ke}. Each was benchmarked across scaling steps, with performance tracked as relative throughput (operations per second).

Table~\ref{tab:hardware-impact} summarizes directional performance trends—whether performance improved, degraded, or remained constant—as well as the average relative performance change per scaling step.

\begin{table}[htbp]
\centering
\begin{threeparttable}
\caption{Summary of workload responses to incremental hardware scaling. Positive average values indicate performance improvement per scaling step.}
\label{tab:hardware-impact}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Metric} & \textbf{CPU cores} & \textbf{Memory (MB)} \\
\midrule
Workloads improved                      & 2/6 (33\%) & 2/6 (33\%) \\
Workloads slowed down                   & 1/6 (17\%) & 1/6 (17\%) \\
Workloads unaffected                    & 3/6 (50\%) & 3/6 (50\%) \\
Average performance change per step (\%)& +6.80\%    & +6.80\%    \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\footnotesize
\item Each increment corresponds to one step increase in CPU cores or memory size.
\item Performance improvements were primarily driven by \texttt{coremark} workloads.
\end{tablenotes}
\end{threeparttable}
\end{table}

These results demonstrate a heterogeneous response to scaling: only one-third of workloads showed any improvement, while the majority exhibited no statistically meaningful gains. Notably, \texttt{coremark} and \texttt{coremark.ke} benefited moderately from increased resources, while other workloads—particularly those involving enclave transitions or cryptographic operations—remained largely invariant or slightly degraded under scaling.

To evaluate the robustness of these trends, we applied both parametric and non-parametric statistical tests. Specifically, one-way ANOVA tested for mean differences across scaling levels, while Kruskal–Wallis and Mann–Whitney U tests evaluated distributional differences without assuming normality. Additionally, Pearson correlation and linear regression were used to quantify trends and explained variance. Results are summarized in Table~\ref{tab:statistical-tests}.

\begin{table}[htbp]
\centering
\caption{Statistical test results for performance scaling across workloads. Parametric and non-parametric tests assess significance of changes with respect to CPU cores and memory.}
\label{tab:statistical-tests}
\begin{subtable}[t]{\textwidth}
\centering
\caption{Parametric Tests: ANOVA, Pearson correlation, and $R^2$.}
\vspace{0.5em}
\begin{tabular}{@{}l
                S[table-format=1.2] S[table-format=1.3]
                S[table-format=1.2] S[table-format=1.3]
                S[table-format=1.3]@{}}
\toprule
\textbf{Workload} 
& \textbf{F (Cores)} & \textbf{p (ANOVA)} 
& \textbf{r (Cores)} & \textbf{p (r)} 
& \textbf{$R^2$} \\
\midrule
\texttt{coremark}      & 1.50 & 0.218 & -0.16 & 0.052 & 0.030 \\
\texttt{coremark.ke}   & 0.01 & 0.975 &  0.00 & 0.999 & 0.000 \\
\texttt{dhrystone}     & 0.28 & 0.837 &  0.07 & 0.374 & 0.005 \\
\texttt{enclave.ke}    & 0.01 & 0.998 &  0.00 & 0.961 & 0.000 \\
\texttt{kyber}         & 1.56 & 0.202 & -0.17 & 0.053 & 0.036 \\
\texttt{kyber.ke}      & 0.00 & 1.000 &  0.00 & 1.000 & 0.000 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\footnotesize
\item Parametric tests assume normal distributions.
\item r: Pearson correlation; $R^2$: variance explained by linear regression.
\end{tablenotes}
\end{subtable}

\vspace{1.5em}

\begin{subtable}[t]{\textwidth}
\centering
\caption{Non-Parametric Tests: Kruskal–Wallis and Mann–Whitney U.}
\vspace{0.5em}
\begin{tabular}{@{}l
                S[table-format=2.2] S[table-format=1.3]
                S[table-format=2.2] S[table-format=1.3]@{}}
\toprule
\textbf{Workload} 
& \textbf{KW (H)} & \textbf{p (KW)} 
& \textbf{MWU (U)} & \textbf{p (MWU)} \\
\midrule
\texttt{coremark}      & 3.60 & 0.057 & 10.00 & 0.052 \\
\texttt{coremark.ke}   & 0.00 & 1.000 & 15.00 & 0.999 \\
\texttt{dhrystone}     & 0.20 & 0.654 & 14.00 & 0.374 \\
\texttt{enclave.ke}    & 0.01 & 0.961 & 15.00 & 0.961 \\
\texttt{kyber}         & 3.75 & 0.053 & 10.00 & 0.053 \\
\texttt{kyber.ke}      & 0.00 & 1.000 & 15.00 & 1.000 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\footnotesize
\item KW: Kruskal–Wallis H-statistic; MWU: Mann–Whitney U-statistic.
\item Non-parametric tests used due to small sample sizes and potential non-normality.
\end{tablenotes}
\end{subtable}
\end{table}

None of the statistical tests yielded significant $p$-values at the $\alpha = 0.05$ level, though \texttt{coremark} and \texttt{kyber} approached marginal significance in the Kruskal–Wallis and Mann–Whitney U tests. However, even in these cases, Pearson correlations and $R^2$ values indicate weak or negligible effect sizes. These results strongly suggest that, for most workloads, hardware scaling does not yield statistically meaningful performance improvements.

This interpretation is further supported by linear regression analysis in Table~\ref{tab:regression}, which reports slope coefficients and intercepts for each workload's performance as a function of core count and memory.

\begin{table}[htbp]
\centering
\begin{threeparttable}
\caption{Linear regression coefficients of performance on hardware parameters. Positive values indicate performance gains; negative values indicate degradation.}
\label{tab:regression}
\begin{tabular}{@{}l
                S[table-format=7.3]
                S[table-format=7.3]
                S[table-format=7.3]@{}}
\toprule
\textbf{Workload} & \textbf{Intercept} & \textbf{Cores Coef.} & \textbf{Memory Coef.} \\
\midrule
\texttt{coremark}     & 2852.203  & 408.000  & 25.000  \\
\texttt{coremark.ke}  & 5006.875  & 0.000    & 0.000   \\
\texttt{dhrystone}    & 1327.375  & -53.750  & -37.500  \\
\texttt{enclave.ke}   & 5046.875  & 0.000    & 0.000   \\
\texttt{kyber}        & 2847.875  & -45.625  & -16.250  \\
\texttt{kyber.ke}     & 5352.250  & 0.000    & 0.000   \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\footnotesize
\item Coefficients reflect linear regression fits across scaling increments.
\item Intercept approximates baseline performance; coefficients represent change per incremental unit of cores or memory.
\end{tablenotes}
\end{threeparttable}
\end{table}

Here again, \texttt{coremark} is the only workload to exhibit a positive response to hardware scaling, albeit with limited effect size. All enclave workloads display near-zero or flat regression slopes, underscoring the notion that scaling is generally ineffective when trusted execution overheads dominate the execution path.

In summary, while modest improvements are observed for select CPU-bound native workloads, scaling core or memory resources yields no consistent benefit—and occasionally even degrades performance—under enclave execution. These findings highlight the need for deeper architectural or runtime co-optimization if scaling is to deliver tangible performance benefits in secure embedded platforms.
